<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Title</title>
       <li>
        生成式人工智能中个人信息保护风险的类型化与合作规制
        <br>
        张 涛
        <br>
        中国政法大学 数据法治研究院
        <br>
        摘 要：从数据生命周期的角度看，生成式人工智能在数据收集、数据清理、数据标注、模型训练、模型评估、
        模型部署与推理等阶段均可能引发个人信息保护风险，如未经同意处理个人信息、违反目的明确与最小化原则、
        个人信息滥用及泄露等。然而，位于规制谱系两端的“自上而下的集中式规制”和“自下而上的分散式规制”均存
        在局限性，难以达到预期的规制效果。因此，有必要采用“自中而外的规制方法”,构建合作型规制空间，调整和
        激活不同规制体系的回应性和敏捷性，最终实现生成式人工智能中个人信息保护风险的合作规制。为此，有必要
        建构契合生成式人工智能的科技法律，引入监管沙盒促成行政规制的包容审慎，利用分层治理实现被规制者的自
        我规制，完善评估认证实现社会的第三方规制。
        <br>
        关键词：	生成式人工智能;个人信息保护;规制空间;合作规制;
        <br>
        <span><i>行政法学研究</i>(2024)</span>

        <br>
        <a class="pdf-link" href="./legal/生成式人工智能中个人信息保护风险的类型化与合作规制.html"
           target="_blank">[PDF READ &amp; DOWNLOAD]</a>

    </li>
    <br>
    <li>
        论数字政府中人工智能的法律地位与规范体系——以人工智能立法为背景
        <br>
        刘 绍 宇
        <br>
        浙江大学 光华法学院
        <br>
        摘 要：随着人工智能技术及产业的发展和数字政府建设的不断推进，人工智能在数字政府中的应用越来越频繁，
        程度越来越深，但在提升行政效能和行政质量的同时，也给民主、法治和基本权利保护等公法价值带来极大的冲击。
        为了解决这一问题，将人工智能在法律定位上视为数字时代的行政助手，公共任务民营化的教义学框架便可用于解决
        上述公法价值的协调问题。一方面，行政助手具有一定独立性和自主性，符合目前人工智能向高阶甚至超级人工智能
        发展的趋势。另一方面，公共任务尽管交给了作为行政助手的人工智能，但是其不可逃逸出包括民主原则、法治原则
        和基本权利保护原则等公法义务的约束，国家仍负有保障其合法有效运行的责任。公共部门人工智能的规范体系尽
        管与私人部门相比存在相似之处，但是背后的价值理念和推导逻辑截然不同，应在公法原则指引下建构。未来在人
        工智能立法中，应对公共部门人工智能的应用予以专门规范，突出与私人部门的不同，对透明原则、公平原则和人
        工干预原则予以明文规定。
        <br>
        关键词：	强人工智能;数字政府;公法;行政助手;
        <br>
        <span><i>行政法学研究</i>(2025)</span>

        <br>
        <a class="pdf-link" href="./legal/论数字政府中人工智能的法律地位与规范体系——以人工智能立法为背景.html"
           target="_blank">[PDF READ &amp; DOWNLOAD]</a>

    </li>
    <br>
    <li>
        人工智能使用者的立法定位及其三维规制
        <br>
        郑 志 峰
        <br>
        西南政法大学 科技法学研究院
        <br>
        摘 要：无论《人工智能法》采取何种主体结构，使用者都始终占据重要位置，其核心是使用行为的判定，同时其与
        开发者、提供者具有身份转化关系。设置“人工智能使用者权益保护”专章契合人工智能法的立法目标，可以向世界
        传达中国一以贯之的以人为本的人工智能治理理念，人工智能使用者权益包括知情权、平等权、控制权以及数据权。
        使用者对于预防和管理人工智能风险具有重要作用，《人工智能法》应当系统明确使用者负担合理使用、风险管理、
        监督以及信息提供义务，践行人工智能伦理准则的要求。设置“人工智能使用者责任”有助于完善人工智能的治理结构，
        确保可信人工智能的实现，在行政罚款方面需要综合考虑使用者的性质、类型与规模，同时区分人工智能产品责任
        与应用责任、不同风险的人工智能、辅助型与替代型人工智能来界定使用者的民事侵权责任。
        <br>
        关键词：人工智能法;使用者;权益保护;义务内容;责任承担;
        <br>
        <span><i>行政法学研究</i>(2025)</span>

        <br>
        <a class="pdf-link" href="./legal/人工智能使用者的立法定位及其三维规制.html"
           target="_blank">[PDF READ &amp; DOWNLOAD]</a>

    </li>
    <br>
    <li>
        人工智能嵌入行政执法的法理分析：现状、风险与应对
        <br>
        黎 慈
        <br>
        江苏警官学院 华中师范大学
        <br>
        摘 要：人工智能嵌入行政执法是政府治理现代化的重要标志与未来走向。与传统行政执法相比，当前人工智能执法
        技术的应用呈现出对数据、算法与算力技术的依赖，以及全自动行政与半自动行政并存、智能执法应用广泛等特征。
        上述特征与执法场景固有特性的融合交叠容易诱发行政执法权的固有属性被侵蚀、行政执法程序的完整性受损害、
        行政执法责任分摊难辨识等潜在法律风险。为了有效防范风险，推动人工智能执法的健康有序发展，应当明确人工
        智能行政执法遵循的基本原则、提升行政执法者人工智能的应用能力、保障人工智能行政执法程序的透明、界定人
        工智能行政执法的责任归属和定位人工智能执法的辅助工具地位。
        <br>
        关键词：	人工智能;行政执法;权利保障;风险规制;
        <br>
        <span><i>湖北社会科学 </i>(2020)</span>

        <br>
        <a class="pdf-link" href="./legal/人工智能嵌入行政执法的法理分析：现状、风险与应对.html"
           target="_blank">[PDF READ &amp; DOWNLOAD]</a>

    </li>
    <br>
    <li>
        生成式人工智能训练阶段的数据法律问题及其立法建议
        <br>
        丁 道 勤
        <br>
        北京航空航天大学 人文与社会科学高等研究院
        <br>
        摘 要：生成式人工智能训练阶段的数据收集和处理面临众多法律问题，在全球层面引发各类诉讼案件。
        训练阶段的数据保护问题集中于预训练和模型微调环节，涉及数据来源合法性、数据质量管理、公开数据
        不当抓取利用、个人数据权利保护缺失、违法偏见和歧视等问题。对于训练阶段的数据治理路径选择，欧盟
        和美国等典型国家和地区呈现出不同的特征，欧盟采取分类分级分主体理念，重点关注训练数据透明度，
        美国对公开可得个人信息持积极利用态度，探索公共数据收集豁免，英国提出合法利益评估标准三步测试，
        新加坡创设数据处理的业务改进和科研例外制度等。生成式人工智能仍在持续进化，为解决训练阶段的
        数据法律问题，在宏观层面，我国需要保持人工智能产业发展和安全监管之间的平衡，推进产业促进政策法制化，
        坚持包容审慎和分类分级监管立法导向，建立适合我国人工智能产业发展阶段的监管沙盒等实验性监管制度；
        在具体数据规则建构方面，有待区分研发训练和商用提供阶段，建立安全港制度，引入科研和业务改进例外的
        数据合理使用制度，进一步细化公开数据利用规则，加强数据质量管理，统一数据匿名化标准，创建机器学习场
        景下处理数据的新权利和新规则，合理地构建起我国生成式人工智能训练数据的数据治理体系。
        <br>
        关键词：	生成式人工智能;训练数据;数据法律问题;数据治理体系;
        <br>
        <span><i>行政法学研究</i>(2024)</span>

        <br>
        <a class="pdf-link" href="./legal/生成式人工智能训练阶段的数据法律问题及其立法建议.html"
           target="_blank">[PDF READ &amp; DOWNLOAD]</a>

    </li>
    <br>
    <li>
        自动化行政裁量的包容性规制
        <br>
        赵 龙
        <br>
        山西大学 法学院
        <br>
        摘 要：我国的自动化行政裁量应用在政策推动下处于世界领先水平，但存在数据瑕疵、转译偏差、算法黑箱等
        基础诱因，易产生行政权利与义务被技术性悬置、官僚系统越权与卸责蔓延、机械裁量与个案正义相冲突等负外
        部效应。若要科学解决这些基础问题及其负外部效应，则需改进既有的发展优位规制模式，构建兼顾创新发展与
        合理规制的包容性规制框架。在以人为本与权利保障双向融合的技术赋权趋势下，自动化行政裁量的技术创新应
        注重提升公民参与行政活动的信息能力。技术性正当程序是正当程序的数字化升级与过程论阐释，有助于推动自
        动化行政裁量应用边界的划定与实质化人工干预机制的构建。
        <br>
        关键词：	人工智能;自动化行政裁量;技术性正当程序;包容性规制;
        <br>
        <span><i>行政法学研究</i>(2025)</span>

        <br>
        <a class="pdf-link" href="./legal/自动化行政裁量的包容性规制.html"
           target="_blank">[PDF READ &amp; DOWNLOAD]</a>

    </li>
    <br>
    <li>
        人工智能时代自动化行政的实践困境及规制路径
        <br>
        戚 莹; 高 文 英
        <br>
        中国人民公安大学
        <br>
        摘 要：自动化行政，是人工智能在行政领域的具体运用，不仅减轻和分担了行政机关的工作任务，还避
        免了人工的恣意和偏私，极大地提高了行政管理与服务的效率和水平。探究自动化行政的内涵、主体范围、
        行为性质，以及它在实践层面的应用局限性和法律风险，如评判失误的风险、传统行政程序被挑战的风险、
        机器故障与数据泄露的风险、算法的“囚徒”风险等就显得尤为重要。考察国外自动化行政的立法实践，
        总结相关立法的特点与经验，并提出对我国的借鉴意义。亟须结合我国当前的立法规定和实践状况，通过
        厘清自动化行政的法律责任、保障行政相对人的程序参与权、细化行政裁量基准、加强对公民隐私权的
        保护、引进和培养复合型人才等途径和方式，提高自动化行政的建设水平，实现信息技术、政府管理和法治
        国家的深度融合。
        <br>
        关键词：人工智能;自动化行政;实践困境;法律风险;法律规制;
        <br>
        <span><i>中国人民公安大学学报(社会科学版)</i>(2022)</span>

        <br>
        <a class="pdf-link" href="./legal/人工智能时代自动化行政的实践困境及规制路径.html"
           target="_blank">[PDF READ &amp; DOWNLOAD]</a>

    </li>
    <br>
    <li>
        技术性正当程序：人工智能时代程序法和算法的双重变奏
        <br>
        刘 东 亮
        <br>
        西安交通大学 法学院
        <br>
        摘 要：人工智能的广泛运用正在重塑政府的运作方式，现代社会的权力形态和权力结构均发生改变，
        算法权力悄然兴起。与此同时，传统行政程序在人工智能的适用场景中失去了原有的效用，诸如“听取
        意见”、“说明理由”等权利保障措施，对于瞬间即作出决定的自动化机器几无适用的余地，这意味着行
        政法的关注焦点需要从传统行政程序向计算机程序算法拓展。对算法权力的规制和监督，需要从算法设计
        的源头构建“技术性正当程序”，即通过程序的代码化实现下列要求：算法公开、透明并具有程序一致性；
        算法具有可解释性，能提供决策的相关逻辑和实质性信息；对决策结果允许质疑，在专业人员协助下审查
        算法，有错误及时修正，等等。技术性正当程序要求行政法与时俱进，跟得上技术发展的步伐。
        <br>
        关键词：人工智能;算法权力;算法设计;技术性正当程序;
        <br>
        <span><i>比较法研究 </i>(2020)</span>

        <br>
        <a class="pdf-link" href="./legal/技术性正当程序：人工智能时代程序法和算法的双重变奏.html"
           target="_blank">[PDF READ &amp; DOWNLOAD]</a>

    </li>
    <br>
    <li>
        人工智能时代的制度安排与法律规制
        <br>
        吴 汉 东
        <br>
        中南财经政法大学 知识产权研究中心
        <br>
        摘 要：人工智能是人类社会的伟大发明, 同时也存有巨大的社会风险。它或是“技术—经济”决策导致的
        风险, 也可能是法律保护的科技文明本身带来的风险, 这一社会风险具有共生性、时代性、全球性的特点。
        同时, 智能革命对当下的法律规则和法律秩序带来一场前所未有的挑战, 在民事主体法、著作权法、侵
        权责任法、人格权法、交通法、劳动法等诸多方面与现有法律制度形成冲突, 凸显法律制度产品供给的
        缺陷。对于人工智能引发的现代性的负面影响, 有必要采取风险措施, 即预防性行为和因应性制度。面向
        未来时代的调整规范构成, 应以人工智能的发展与规制为主题, 形成制度性、法治化的社会治理体系,
        包括以安全为核心的法律价值目标、以伦理为先导的社会规范调控体系和以技术、法律为主导的风险控制
        机制。借鉴国外经验, 立足本土需要, 当前应尽快出台“国家发展战略”, 及时制定“机器人伦理章程”,
        适时进行机器人专门立法。
        <br>
        关键词：	人工智能;社会风险;法律挑战;制度安排;
        <br>
        <span><i>法律科学(西北政法大学学报)</i>(2017)</span>

        <br>
        <a class="pdf-link" href="./legal/人工智能时代的制度安排与法律规制.html"
           target="_blank">[PDF READ &amp; DOWNLOAD]</a>

    </li>
    <br>
    <li>
        论算法认知偏差对人工智能法律规制的负面影响及其矫正
        <br>
        刘 泽 刚
        <br>
        西南政法大学 行政法学院
        <br>
        摘 要：算法认知偏差不仅扭曲事实，还影响人工智能法律规制质效。法学文献中的“算法”常用于指代
        影响权益的人工智能系统。不同于传统编程，机器学习算法是通过向数据学习以形成模型。数据、算力、
        AI框架、模型框架、人为干预等因素深刻影响算法作用的发挥。算法并不是对利益得失的精巧算计。
        大部分算法也不具有排他性的财产属性。算法是人工智能体系中相对透明和确定的因素。“算法黑箱”
        并非人为“黑幕”，而是因基本原理所限导致的验证性和解释性的不足。滥用算法概念会导致人工智能法律
        规制的失焦、失据、失鹄、失度。数据法与专门立法相结合是人工智能规制的恰当立法形态。过度强调
        算法不仅造成权利、产业和科技目标难以调和，还可能导致过度监管。算法只有在以人的责任为基础的
        人工智能系统中才能得到稳妥规制。我国未来应该制定人工智能专门立法。业已开展的算法治理不宜过度
        冒进，宜审慎处理好当前与未来、名义与实质、规范与发展的关系。在准确的算法认知指导下，算法备案
        和公示的问题能够得到良好解释和妥善解决。
        <br>
        关键词：算法治理;人工智能法律规制;机器学习;认知偏差;个人数据保护;
        <br>
        <span><i>政治与法律</i>(2022)</span>

        <br>
        <a class="pdf-link" href="./legal/论算法认知偏差对人工智能法律规制的负面影响及其矫正.html"
           target="_blank">[PDF READ &amp; DOWNLOAD]</a>

    </li>
    <br>
    <li>
        人工智能时代行政执法问题研究
        <br>
        邓 晔; 王 晨 屹; 洪 琨 凯
        <br>
        宜春学院 政法学院
        <br>
        摘 要：传统行政执法在人工智能时代正在受到挑战。智能算法、执法数据安全、执法主体责任、行政执法
        行为预测等都将在人工智能的辅助下变得更加智能，一言以蔽之，人工智能时代必将深度参与并改变传统
        行政执法模式、执法理念和执法效果。因此，研究人工智能时代的行政执法问题能为各级行政执法机关应对
        未来及已来的挑战提供有益的参考。
        <br>
        关键词：人工智能;算法;行政主体;行政执法;
        <br>
        <span><i>宜春学院学报</i>(2023)</span>

        <br>
        <a class="pdf-link" href="./legal/人工智能时代行政执法问题研究.html"
           target="_blank">[PDF READ &amp; DOWNLOAD]</a>

    </li>
    <br>
    <li>
        数字行政的算法风险及法律规制_法国经验与中国意义
        <br>
        杨 一 健; 王 锡 锌
        <br>
        蒙彼利埃大学法学院; 北京大学法学院
        <br>
        摘 要：公共行政数字化、算法化已成为数字化时代行政技术变迁的趋势。从行政法治角度看，如何对算法风险进行
        法律规制，渐成行政法组织和制度变革的重大命题。将算法引入行政活动，在提高行政效益的同时，亦带来前所未有
        的风险。对算法行政之风险的应对及管理，是行政法制度面临的一个普遍性挑战。在这个意义上，域外经验具有
        很强的本土意义。法国行政法从规范“基于算法作出的具体行为”的角度，展开算法行政法律规制的制度探索。
        从法律实践观察，以算法行政公开透明为中心的行政法规制框架虽具有一定效用，但无法有效应对多元的复合风险。
        对算法行政进行法律规制，需要在强调算法公开透明的基础上，进一步从源代码合理性、转译可靠性、数据源
        合法性、算法行政可诉性等维度展开系统性的规制。
        <br>
        关键词：	法国行政法;算法行政;具体行政行为;合法性审查;制度规制;
        <br>
        <span><i>行政法学研究</i>(2024)</span>

        <br>
        <a class="pdf-link" href="./legal/数字行政的算法风险及法律规制_法国经验与中国意义.html"
           target="_blank">[PDF READ &amp; DOWNLOAD]</a>

    </li>
    <br>
    <li>
        数字时代行政法的发展
        <br>
        徐 继 敏
        <br>
        四川大学 法学院
        <br>
        摘 要：数字时代政府由实体型向平台型转变、行政关系由封闭向开放转变、智慧行政越来越普遍，数字治理
        促进政府内部纵向、横向协调，政府以整体形象出现。行政组织法规范的重点应从分权、赋权、确权向行政机
        关之间的协助、配合转变以促进整体型治理。行政行为格式化、在线化、智慧化，数字治理让政府更强大，
        让行政证明更容易，有效控制行政权力成为行政行为法的首要任务，技术规范、技术标准等软法规则成为行政法
        的重要内容。数字治理改变传统行政管辖关系、启动程序及协助关系，行政程序法需规定行政机关之间数据共享、
        协同调查取证、协助审查判断证据、协同决策、协助执行等规则，减少行政程序证明对象，可以适当提高证明
        标准，将原由申请人承担的部分证明责任转移至行政机关。
        <br>
        关键词：数字政府;数字时代;行政法;行政法发展;
        <br>
        <span><i>行政法学研究</i>(2024)</span>

        <br>
        <a class="pdf-link" href="./legal/数字时代行政法的发展.html"
           target="_blank">[PDF READ &amp; DOWNLOAD]</a>

    </li>
    <br>
    <li>
        总体国家安全观视域下的算法安全及其风险治理
        <br>
        张 龙 辉
        <br>
        东北师范大学政法学院; 南开大学中国政府发展联合研究中心
        <br>
        摘 要：[研究目的]算法国家安全属性的凸显使算法安全成为国家安全建设不可回避的现实问题，探讨算法
        安全及其风险治理，能够为有效应对算法安全风险、提升国家安全韧性提供理论借鉴。[研究方法]通过理论
        分析、案例研究和归纳演绎方法，总结算法安全风险及其生成原因，探讨算法安全风险对国家安全的挑战及
        其治理路径。[研究结果/结论]总体国家安全观视域下的算法安全包括算法自身安全和算法运行引发的安全
        两个方面。算法模型漏洞、运行环境变化、有组织的算法攻击以及算法迭代落后等会引发算法安全风险，
        危及国土安全和数字主权，引发国家意识形态安全危机，催生经济社会安全风险，还会导致普遍的国家间
        安全困境。需要持续推进算法开源与转化，优化算法模型，完善算法功能，加强算法运行的制度监管和技术
        监管，打造完整的算法产业链，以充分发挥算法赋能国家安全的技术优势。
        <br>
        关键词：总体国家安全观;算法安全;基础性安全;复合型地位;算法风险治理;
        <br>
        <span><i>情报杂志</i>(2025)</span>

        <br>
        <a class="pdf-link" href="./legal/总体国家安全观视域下的算法安全及其风险治理.html"
           target="_blank">[PDF READ &amp; DOWNLOAD]</a>

    </li>
    <br>
    <li>
        生成式人工智能治理的逻辑更新与路径优化——以人机关系为视角
        <br>
        韩 旭 至
        <br>
        华东政法大学 法律学院
        <br>
        摘 要：生成式人工智能技术塑造了人机共生的新型关系，不能简单等同于深度合成技术、智能交互技术、
        高风险人工智能。新型的人机关系中，既存在人的自主性危机，也有被放大的人工智能治理风险。在风险
        应对的逻辑中，生成式人工智能的定位应从“老师”转向“伙伴”,不应对服务提供者提出过高要求并作简单
        的结果评价；同时，应将治理维度从算法治理拓展到用户治理之中。在具体的治理路径上，首先应坚持包容
        审慎原则，设置过程义务及对应的责任豁免规则；其次，在高风险场景中，应持续进行风险影响评估、
        充分保证人类监督并提升算法透明度；最后，应通过伦理审查、行业自律、数字素养提升的伦理治理方案
        以捍卫人的自主性。
        <br>
        关键词：ChatGPT;生成式人工智能;算法治理;场景化治理;人机交互;
        <br>
        <span><i>行政法学研究</i>(2023)</span><br>

        <a class="pdf-link" href="./legal/生成式人工智能治理的逻辑更新与路径优化——以人机关系为视角.html"
           target="_blank">[PDF READ &amp; DOWNLOAD]</a>

    </li>
    <br>
    <li>
        生成式AI对个人信息保护的挑战与风险规制
        <br>
        黄 锫
        <br>
        同济大学 法学院
        <br>
        摘 要：生成式AI的技术特性使其对《个人信息保护法》建构的个人信息保护体系产生了挑战,主要包括:
        生成式AI虽然解决了让语言模型使用超大体量无人工标注数据进行预训练的难题,但其采用的技术路线也使
        大语言模型成为完全的“技术黑箱”,进而使开发者难以遵守个人信息处理的知情同意规则;无论是依据“目的
        限定原则”还是“场景理论”,生成式AI的技术特性都使其难以满足在“合理范围”内处理已公开个人信息的
        法定要求;生成式AI的技术特性使大语言模型的输入端和输出端都存在对信息主体的敏感个人信息权益和
        个体隐私权的侵害风险。我们应该基于“包容审慎”的基本风险规制理念,通过调整生成式AI领域知情同意
        规则的适用方式、重塑生成式AI领域已公开个人信息的处理规则、设立生成式AI领域个人信息中人格权
        保护的行政规制措施等途径,实现创新技术发展和个人信息保护之间的平衡。
        <br>
        关键词：	生成式人工智能;ChatGPT;个人信息;风险规制;
        <br>
        <span><i>现代法学</i>(2024)</span><br>

        <a class="pdf-link" href="./legal/生成式AI对个人信息保护的挑战与风险规制.html"
           target="_blank">[PDF READ &amp; DOWNLOAD]</a>

    </li>


    </ul>
    </section>
</main>


</html>